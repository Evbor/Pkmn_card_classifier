{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokemon Card Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "import sklearn.model_selection as ms\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def print_experiments(mnt_pt):\n",
    "    for experiment in os.listdir(mnt_pt):\n",
    "        experiment_path = mnt_pt + '/' + experiment\n",
    "        print('Experiment {0} directory: {1}'.format(experiment, experiment_path))\n",
    "        for directory in os.listdir(experiment_path):\n",
    "            if directory == 'dataset':\n",
    "                print('dataset path: {} \\n'.format(experiment_path + '/' + directory))\n",
    "            else:\n",
    "                print('no dataset directory in experiment directory: {0}, subdirectories are: {1}'.format(experiment, os.listdir(experiment_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment base_set_classifier directory: data/base_set_classifier\n",
      "dataset path: data/base_set_classifier/dataset \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnt_pt = 'data'\n",
    "print_experiments(mnt_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constants\n",
    "# file constants\n",
    "dataset_path = 'data/base_set_classifier/dataset'\n",
    "# data properties\n",
    "img_size = (550,400) # (height, width) in pixels\n",
    "color_mode = 'rgb'\n",
    "batch_size = 32\n",
    "random_seed = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10984 images belonging to 2 classes.\n",
      "Dictionary mapping classes to numerical labels: {'not_base_set': 1, 'base_set': 0}\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator().flow_from_directory(dataset_path, target_size=(550,400), color_mode='rgb', batch_size=32, class_mode='binary',\n",
    "                                                          shuffle=True, seed=42)\n",
    "encoding_map = data_generator.class_indices\n",
    "print('Dictionary mapping classes to numerical labels: {}'.format(encoding_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Frequency Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in not_base_set class: 10882\n",
      "Number of samples in base_set class: 102\n",
      "Expected value for probability of drawing a not_base_set sample from our dataset: 0.9907137654770576\n",
      "Expected value for probability of drawing a base_set sample from our dataset: 0.009286234522942461\n"
     ]
    }
   ],
   "source": [
    "all_labels = data_generator.labels\n",
    "label_counts = np.asarray([np.sum((all_labels == label).astype(np.int32)) for label in encoding_map.values()])\n",
    "plt.bar(encoding_map.values(), label_counts)\n",
    "plt.xticks(list(encoding_map.values()), list(encoding_map.keys()))\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Frequency of Classes')\n",
    "plt.show()\n",
    "label_frequencies = label_counts / len(all_labels)\n",
    "for name, num in np.squeeze(np.dstack((np.asarray(list(encoding_map.keys())), label_counts))):\n",
    "    print('Number of samples in {0} class: {1}'.format(name, num))\n",
    "for name, freq in np.squeeze(np.dstack((np.asarray(list(encoding_map.keys())), label_frequencies))):\n",
    "    print('Expected value for probability of drawing a {0} sample from our dataset: {1}'.format(name, freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see from the above histogram that our dataset is very unbalanced and that we can expect an average (expected value) accuracy of 0.9907 for classification if we constructed a model that only predicted not_base_set for all examples in our sample dataset since the probability of encountering a non_base_set example is 0.9907. A classifier of this design would have great accuracy scores but would have trouble predicting examples that are truely base_set. This suggests that classification accuracy might not be the best measure of our models performance and that maybe we should look at the precision, recall, and F1 scores of our specific classes. Assuming our dataset sample is a representative sample of the total population of all possible base set pokemon card images and non base set pokemon card images that will ever be uploaded to the app then there would be no issue with the unbalancedness of this dataset, but if it isn't a representative sample of the population then our classifier would have a heavy bias on predicting not base set. This assumption is unlikely to be valid because there is no good reason to suggest that users would prefer to upload more images of one class than the other. Which means that a classifier trained on this dataset and cross validated for highest accuracy would most likely be heavily biased on labeling examples as non base set, and would perform pretty poorly when deployed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways we can deal with the above problem.\n",
    "1. Undersample our most represented class, and maximize accuracy when we think our sample is representative. The issue though is the amount of examples of our under represented class (or over represented class after undersampling) might not be enough for our model to learn to identify them, and we would have to bias our model more in order to achieve better results (but overall worse results than our higher variance model trained on more data)\n",
    "2. Oversample our under represented class, and maximize accuracy when we think our sample is representative. The issue with this solution is that at some point if we oversample too much the model might overtrain on the under represented class and not generalize well in deployment.\n",
    "3. Oversample our under represented class with image augmentation. Again the downside to this solution is that our image augmentation might not be strong enough to produce examples that are different enough from the ones we started with and this will eventually cause overtraining.\n",
    "4. Brute force search for model architectures that can learn to maximize our precision, recall, and F1 metrics from the limited amount of data we have for our under represented class. The problem with this solution is that the models we might find might not perform as well as we want on these metrics because the models that are capable of learning from our limited amount of data for our under represented class might be heavily biased, making the overall scores on our metrics not high.\n",
    "5. Change our loss function to penalize wrong classification of the under represented class more than that of the over represented class.\n",
    "6. Gather more data!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are more concerned with our model identifying base set examples than non base set examples the metrics we should be concerned with are the precision, recall and F1 scores for our base set class. **Since recall is essentially our accuracy score on predicting base set examples, and precision is our measure of certainty on our predictions of base set, we naturally would want to maximize both. This implies we should maximize our F1 score since it is the unweighted harmonic mean of our precision and recall scores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solutions 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def compresssed_dataset(dataset_path):\n",
    "    classes = os.listdir(dataset_path)\n",
    "    ds = []\n",
    "    for c in classes:\n",
    "        class_path = dataset_path + '/' + c\n",
    "        imgs_of_c = os.listdir(class_path)\n",
    "        ext = lambda img: class_path + '/' + img\n",
    "        imgpaths_of_c = list(map(ext, imgs_of_c))\n",
    "        samples_of_c = list(zip(imgpaths_of_c, [c for _ in range(len(imgpaths_of_c))]))\n",
    "        ds.extend(samples_of_c)\n",
    "    ds = np.asarray(ds)        \n",
    "    return ds\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def stratified_partitions(k, dataset_path, seed=None):\n",
    "    random.seed(seed)\n",
    "    classes = os.listdir(dataset_path)\n",
    "    samples_of_classes = []\n",
    "    for c in classes:\n",
    "        samples_of_c = os.listdir(dataset_path + '/' + c)\n",
    "        samples_of_c = list(zip(samples_of_c, [c for _ in range(len(samples_of_c))]))\n",
    "        random.shuffle(samples_of_c)\n",
    "        samples_of_classes.append(samples_of_c)\n",
    "    if (min(list(map(len, samples_of_classes))) / k) < 1:\n",
    "        raise Exception(\"cannot partition datset into {0} partitions and still keep each partition startified\".format(k))\n",
    "    partitions_of_classes = [[samples_of_class[i * (len(samples_of_class) // k) + min(i, len(samples_of_class) % k):(i+1) * (len(samples_of_class) // k) +\n",
    "                                               min(i+1, len(samples_of_class) % k)] for i in range(k)] for samples_of_class in samples_of_classes]\n",
    "    partitions = []\n",
    "    num_classes = len(partitions_of_classes)\n",
    "    for i in range(k):\n",
    "        partition = []\n",
    "        for c in range(num_classes):\n",
    "            partition.extend(partitions_of_classes[c][i])\n",
    "        random.shuffle(partition)\n",
    "        partitions.append(partition)\n",
    "    return partitions\n",
    "\n",
    "\"\"\"\n",
    "samples_per_class: dictionary, with keys that are the names of the different classes, and values that are the number of samples to draw from a specified \n",
    "                   class.\n",
    "dataset_path: string or numpy array, a path to dataset with subfolders containing samples of a specific class with the name of the class as the \n",
    "              subfolde, or a numpy array where each row is a sample and the first column is filename and the second is label\n",
    "replacement: dictionary, with keys that are the names of the different classes, and values that are boolean which specify whether sampling from the\n",
    "             specified class should be done with replacement (True) or not (False)\n",
    "\n",
    "returns: numpy array, of tuples, containing (path to image, label) representing the sampled dataset from the original dataset.\n",
    "\"\"\"\n",
    "def sample_dataset(samples_per_class, dataset, replacement, seed=None):\n",
    "    random.seed(seed)\n",
    "    sampled_set = []\n",
    "    classes = np.unique(dataset[:,1])\n",
    "    if samples_per_class == None:\n",
    "        samples_per_class = {c: np.sum(dataset[:,1] == c) for c in classes}\n",
    "    if replacement == None:\n",
    "        replacement = {c: False for c in classes}\n",
    "    for c in classes:\n",
    "        imgpaths_per_c = dataset[dataset[:,1] == c]\n",
    "        idx = np.random.choice(len(imgpaths_per_c), size=samples_per_class[c], replace=replacement[c])\n",
    "        sampled_set.extend(imgpaths_per_c[idx])       \n",
    "    return np.asarray(sampled_set)  \n",
    "\n",
    "def encode(label):\n",
    "    encoding = {'base_set': '1', 'not_base_set': '0'}\n",
    "    return encoding[label]\n",
    "\n",
    "def encode_dataframe(df):\n",
    "    df['class'] = df['class'].map(encode)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training set: 6590\n",
      "Number of samples in the validation set: 2197\n",
      "Number of samples in the test set: 2197\n",
      "\n",
      "Number of base_set samples in training set: 61\n",
      "Number of not_base_set samples in training set: 6529\n",
      "\n",
      "Number of base_set samples in validation set: 21\n",
      "Number of not_base_set samples in validation set: 2176\n",
      "\n",
      "Number of base_set samples in test set: 20\n",
      "Number of not_base_set samples in test set: 2177\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into a train set, validation set, and test set\n",
    "test_proportion = 1/5\n",
    "val_proportion = 1/5\n",
    "\n",
    "ds = compresssed_dataset(dataset_path)\n",
    "filenames, labels = ds[:,0], ds[:,1]\n",
    "names = np.unique(labels)\n",
    "\n",
    "filenames_train_val, filenames_test, labels_train_val, labels_test = ms.train_test_split(filenames, labels, test_size=test_proportion, stratify=labels,\n",
    "                                                                                         random_state=random_seed)\n",
    "filenames_train, filenames_val, labels_train, labels_val = ms.train_test_split(filenames_train_val, labels_train_val, \n",
    "                                                                               test_size=(val_proportion/(1 - test_proportion)), \n",
    "                                                                               stratify=labels_train_val, random_state=random_seed)\n",
    "train_size = len(filenames_train)\n",
    "val_size = len(filenames_val)\n",
    "test_size = len(filenames_test)\n",
    "print('Number of samples in the training set: {}'.format(train_size))\n",
    "print('Number of samples in the validation set: {}'.format(val_size))\n",
    "print('Number of samples in the test set: {}\\n'.format(test_size))\n",
    "for name in names:\n",
    "    num_of_name = np.sum(labels_train == name)\n",
    "    print('Number of {0} samples in training set: {1}'.format(name, num_of_name))\n",
    "print('')\n",
    "for name in names:\n",
    "    num_of_name = np.sum(labels_val == name)\n",
    "    print('Number of {0} samples in validation set: {1}'.format(name, num_of_name))\n",
    "print('')\n",
    "for name in names:\n",
    "    num_of_name = np.sum(labels_test == name)\n",
    "    print('Number of {0} samples in test set: {1}'.format(name, num_of_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling and downsampling datasets\n",
    "\n",
    "class_samples_train = {'base_set': 100, 'not_base_set': 100}\n",
    "class_samples_val = {'base_set': 40, 'not_base_set': 40}\n",
    "class_samples_test = None\n",
    "\n",
    "replacement_train = {'base_set': True, 'not_base_set': False}\n",
    "replacement_val = {'base_set': True, 'not_base_set': False}\n",
    "replacement_test = None\n",
    "\n",
    "filenames_train, labels_train = sample_dataset(class_samples_train, np.squeeze(np.dstack((filenames_train, labels_train))), replacement_train, seed=random_seed).T\n",
    "filenames_val, labels_val = sample_dataset(class_samples_val, np.squeeze(np.dstack((filenames_val, labels_val))), replacement_val, seed=random_seed).T\n",
    "filenames_test, labels_test = sample_dataset(class_samples_test, np.squeeze(np.dstack((filenames_test, labels_test))), replacement_test, seed=random_seed).T\n",
    "\n",
    "train_pd = encode_dataframe(pd.DataFrame({'filename': filenames_train, 'class': labels_train}))\n",
    "\n",
    "val_pd = encode_dataframe(pd.DataFrame({'filename': filenames_val, 'class': labels_val}))\n",
    "test_pd = encode_dataframe(pd.DataFrame({'filename': filenames_test, 'class': labels_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data/base_set_classifier/dataset/base_set/swit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/base_set_classifier/dataset/base_set/star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>data/base_set_classifier/dataset/base_set/lass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>data/base_set_classifier/dataset/base_set/vulp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>data/base_set_classifier/dataset/base_set/ener...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                           filename\n",
       "0     1  data/base_set_classifier/dataset/base_set/swit...\n",
       "1     1  data/base_set_classifier/dataset/base_set/star...\n",
       "2     1  data/base_set_classifier/dataset/base_set/lass...\n",
       "3     1  data/base_set_classifier/dataset/base_set/vulp...\n",
       "4     1  data/base_set_classifier/dataset/base_set/ener..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 validated image filenames belonging to 2 classes.\n",
      "Found 80 validated image filenames belonging to 2 classes.\n",
      "Found 2197 validated image filenames belonging to 2 classes.\n",
      "{'0': 0, '1': 1}\n",
      "{'0': 0, '1': 1}\n",
      "{'0': 0, '1': 1}\n"
     ]
    }
   ],
   "source": [
    "# Augmenting datasets \n",
    "train_datagen = ImageDataGenerator(height_shift_range=0.5, rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "valid_datagen = ImageDataGenerator(height_shift_range=0.5, rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "test_datagen = ImageDataGenerator(height_shift_range=0.5, rotation_range=90, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_pd, target_size=img_size, class_mode='binary', batch_size=batch_size, drop_duplicates=False, seed=random_seed)\n",
    "valid_generator = valid_datagen.flow_from_dataframe(val_pd, target_size=img_size, class_mode='binary', batch_size=batch_size, drop_duplicates=False, seed=random_seed)\n",
    "test_generator = test_datagen.flow_from_dataframe(test_pd, target_size=img_size, class_mode='binary', batch_size=batch_size, drop_duplicates=False, seed=random_seed)\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "print(valid_generator.class_indices)\n",
    "print(test_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(): \n",
    "    inputs = k.Input(shape=(*img_size, 3))\n",
    "    x = k.layers.Conv2D(5, (2,2), strides=(1,1), padding='same', \n",
    "                      input_shape=(*img_size, 3), activation='relu')(inputs)\n",
    "    x = k.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid')(x)\n",
    "    x = k.layers.Conv2D(10, (5,5), strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = k.layers.MaxPooling2D(pool_size=(5,5), strides=(5,5), padding='valid')(x)\n",
    "    x = k.layers.Conv2D(25, (10,10), strides=(1,1), padding='same', activation='relu')(x)\n",
    "    x = k.layers.MaxPooling2D(pool_size=(10,10), strides=(10,10), padding='valid')(x)\n",
    "    x = k.layers.Flatten()(x)\n",
    "    x = k.layers.Dense(100, activation='relu')(x)\n",
    "    x = k.layers.Dense(40, activation='relu')(x)\n",
    "    x = k.layers.Dense(15, activation='relu')(x)\n",
    "    x = k.layers.Dense(5, activation='relu')(x)\n",
    "    predictions = k.layers.Dense(1, activation='sigmoid', use_bias=False)(x)\n",
    "    model = k.models.Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.001), loss=k.losses.BinaryCrossentropy(),\n",
    "                  metrics=[k.metrics.BinaryAccuracy(), k.metrics.Precision(), k.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Cross-validating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0808 20:29:29.321953 140492141201152 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0808 20:29:29.524790 140492141201152 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 550, 400, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 550, 400, 5)       65        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 275, 200, 5)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 275, 200, 10)      1260      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 40, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 55, 40, 25)        25025     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                4040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                615       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 80        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 81,190\n",
      "Trainable params: 81,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = model_1()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1866s 933ms/step - loss: 0.6744 - binary_accuracy: 0.5936 - precision: 0.7161 - recall: 0.3103 - val_loss: 0.6014 - val_binary_accuracy: 0.7957 - val_precision: 0.7497 - val_recall: 0.8877\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1864s 932ms/step - loss: 0.4400 - binary_accuracy: 0.8344 - precision: 0.8027 - recall: 0.8867 - val_loss: 0.2264 - val_binary_accuracy: 0.8993 - val_precision: 0.8951 - val_recall: 0.9038\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 1861s 931ms/step - loss: 0.1659 - binary_accuracy: 0.9373 - precision: 0.9225 - recall: 0.9548 - val_loss: 0.1702 - val_binary_accuracy: 0.9349 - val_precision: 0.9794 - val_recall: 0.8888\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1862s 931ms/step - loss: 0.1040 - binary_accuracy: 0.9629 - precision: 0.9560 - recall: 0.9705 - val_loss: 0.1749 - val_binary_accuracy: 0.9401 - val_precision: 0.9106 - val_recall: 0.9760\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 1867s 933ms/step - loss: 0.0822 - binary_accuracy: 0.9709 - precision: 0.9660 - recall: 0.9761 - val_loss: 0.1247 - val_binary_accuracy: 0.9506 - val_precision: 0.9433 - val_recall: 0.9588\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1865s 933ms/step - loss: 0.0673 - binary_accuracy: 0.9766 - precision: 0.9719 - recall: 0.9816 - val_loss: 0.1438 - val_binary_accuracy: 0.9472 - val_precision: 0.9423 - val_recall: 0.9528\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1862s 931ms/step - loss: 0.0618 - binary_accuracy: 0.9790 - precision: 0.9755 - recall: 0.9827 - val_loss: 0.1393 - val_binary_accuracy: 0.9506 - val_precision: 0.9567 - val_recall: 0.9438\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1861s 930ms/step - loss: 0.0379 - binary_accuracy: 0.9864 - precision: 0.9843 - recall: 0.9885 - val_loss: 0.1326 - val_binary_accuracy: 0.9592 - val_precision: 0.9560 - val_recall: 0.9625\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1864s 932ms/step - loss: 0.0283 - binary_accuracy: 0.9904 - precision: 0.9888 - recall: 0.9919 - val_loss: 0.1318 - val_binary_accuracy: 0.9528 - val_precision: 0.9542 - val_recall: 0.9514\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1863s 932ms/step - loss: 0.0366 - binary_accuracy: 0.9881 - precision: 0.9875 - recall: 0.9886 - val_loss: 0.1362 - val_binary_accuracy: 0.9551 - val_precision: 0.9439 - val_recall: 0.9679\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, epochs=10, steps_per_epoch=2000, validation_data=valid_generator,\n",
    "                              shuffle=True, validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 70s 1s/step - loss: 0.2576 - binary_accuracy: 0.9363 - precision: 0.1154 - recall: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Evaluating Model\n",
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 02:07:07.416972 140492141201152 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0809 02:07:07.417764 140492141201152 deprecation.py:506] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0809 02:07:07.941749 140492141201152 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0809 02:07:07.942743 140492141201152 export_utils.py:182] Export includes no default signature!\n",
      "W0809 02:07:08.438274 140492141201152 export_utils.py:182] Export includes no default signature!\n"
     ]
    }
   ],
   "source": [
    "# Saving Model\n",
    "\n",
    "k.experimental.export_saved_model(model, 'models')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = k.experimental.load_from_saved_model('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
